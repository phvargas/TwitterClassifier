import sys
import os
import re
from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer
from sklearn.datasets import load_files
from time import strftime, localtime, time
from matplotlib import pyplot as plt
from sklearn.externals import joblib


"""
    Loads persistence model generated by TClassfier.py and given a body of text makes prediction       
"""

__author__ = 'Plinio H. Vargas'
__date__ = 'Mon,  Oct 16, 2017 at 13:44:27'
__email__ = 'pvargas@cs.odu.edu'


def predict(model, category_path, doc):
    """
    :param model: folder where dataset classification sub-folders reside
    :param category_path: path where category model resides
    :param doc: path of document to be compared
    :return: void
    """
    encoding = 'utf-8'
    # get title from folder dataset name
    title = model.split('/')
    if title[-1] == '':
        title.pop()

    title = title[-1]

    # load model into pipeline object
    pipeline = joblib.load(model)

    # load category nomenclature into category object
    category = joblib.load(category_path)

    print('\nLoading harassment dataset files....')
    dataset = load_files(doc, shuffle=False)

    count_vect = CountVectorizer()
    tfidf_transformer = TfidfTransformer()
    X_train_counts = count_vect.fit_transform(dataset.data)

    print('X_train_Counts length', X_train_counts.shape)
    print('Number of documents:', len(dataset.data))

    X_data = tfidf_transformer.fit_transform(X_train_counts)
    print('X_data type:', type(X_data))

    new_doc = []
    for values in dataset.data:
        new_doc.append(values.decode('utf-8'))

    """
    #with open(doc, mode='r') as in_file:
        for record in in_file:
            new_doc.append(record)
    """

    # predict the outcome on the testing set and store it in a variable named y_predicted
    y_predicted = pipeline.predict(new_doc)

    counter = 0
    harassment = 0
    no_harassment = 0
    wrong = 0
    bin = {'0-2': 0, '2-3': 0, '3-3.5': 0, '3.5-': 0}

    tfidf_feature = []
    tfidf_miss_clf = []

    for doc, cat in zip(new_doc, y_predicted):
        if cat != dataset.target[counter]:
            #print('<{0}> {1} => {2}  ==> original class: {3}'.format(counter + 1, doc.strip(), category[cat],
            #                                                         category[dataset.target[counter]]))
            wrong += 1

            tfidf_sum = sum(X_data[counter].toarray()[0])
            tfidf_miss_clf.append(tfidf_sum)

            if tfidf_sum <= 2:
                bin['0-2'] += 1
            elif tfidf_sum <= 3:
                bin['2-3'] += 1
            elif tfidf_sum <= 3.5:
                bin['3-3.5'] += 1
            else:
                bin['3.5-'] += 1

            if category[dataset.target[counter]] == 'harassment':
                harassment += 1
            else:
                no_harassment += 1
        else:
            tfidf_feature.append(sum(X_data[counter].toarray()[0]))
        counter += 1

    print(bin)
    for key in bin:
        print('%s,%d' % (key, bin[key]))

    print('Number of misclassification:', wrong)
    print('Harassment misclassification:', harassment)
    print('No harassment misclassification:', no_harassment)
    print('Success ratio:', (counter - wrong) / counter)

    print('data lenghth', X_data.shape)
    print('cat length', len(dataset.target))

    plt.scatter(range(len(tfidf_feature)), tfidf_feature, color='black')
    plt.scatter(range(len(tfidf_miss_clf)), tfidf_miss_clf, color='red')

    plt.title('Miss Classification of Test Document in no_ambiguous Corpus\n Using  TFIDF Representation ')
    plt.xlabel('Tweet')
    plt.ylabel('Document Sum(TFIDF)')
    plt.show()
    return


def get_filename_sequence(file_path):
    try:
        regex = re.search("(\d+)", file_path.split('/')[-1]).group(1)

    except AttributeError:
        regex = None

    return regex


if __name__ == '__main__':
    """
    :param model_path: path and filename where model resides
    :param cat_path: path and filename for category nomenclature
    :param doc: path and filename where document resides       
    """

    # record running time
    start = time()
    print('Starting Time: %s' % strftime("%a,  %b %d, %Y at %H:%M:%S", localtime()))

    # checks if path was passed as an argument
    if len(sys.argv) != 4:
        print('Usage: python3 Predictor.py <model_path> <cat_path> <doc_path>')
        sys.exit(-1)

    path = sys.argv[1]
    cat_path = sys.argv[2]
    doc_path = sys.argv[3]

    if not os.path.isfile(path):
        print('\nCould not find model in file: %s' % path)
        print('Usage: python3 Predictor.py <model_path> <cat_path> <doc_path>')
        sys.exit(-1)

    if not os.path.isfile(path):
        print('\nCould not find category file: ' % cat_path)
        print('Usage: python3 Predictor.py <model_path> <cat_path> <doc_path>')
        sys.exit(-1)

    if not os.path.isdir(doc_path):
        print('\nCould not find document: ' % doc_path)
        print('Usage: python3 Predictor.py <model_path> <cat_path> <doc_path>')
        sys.exit(-1)

    predict(path, cat_path, doc_path)

    print('\nEnd Time:  %s' % strftime("%a,  %b %d, %Y at %H:%M:%S", localtime()))
    print('Execution Time: %.2f seconds' % (time()-start))
sys.exit(0)
