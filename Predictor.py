import sys
import os
import numpy as np
from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer
from sklearn.linear_model import SGDClassifier
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.datasets import load_files
from sklearn.model_selection import train_test_split
from sklearn import metrics
from time import strftime, localtime, time
from sklearn.model_selection import cross_val_score, cross_val_predict
from sklearn.model_selection import KFold
from scipy.stats import sem
from matplotlib import pyplot as plt
from sklearn.externals import joblib


"""
    Loads persistence model generated by TClassfier.py and given a body of text makes prediction       
"""

__author__ = 'Plinio H. Vargas'
__date__ = 'Mon,  Oct 16, 2017 at 13:44:27'
__email__ = 'pvargas@cs.odu.edu'


def predict(model, category_path, doc):
    """
    :param model: folder where dataset classification sub-folders reside
    :param category_path: path where category model resides
    :param doc: path of document to be compared
    :return: void
    """
    encoding = 'utf-8'
    # get title from folder dataset name
    title = model.split('/')
    if title[-1] == '':
        title.pop()

    title = title[-1]

    # load model into pipeline object
    pipeline = joblib.load(model)

    # load category nomenclature into category object
    category = joblib.load(category_path)

    print('\nLoading harassment dataset files....')
    dataset = load_files(doc, shuffle=False)

    count_vect = CountVectorizer()
    tfidf_transformer = TfidfTransformer()
    X_train_counts = count_vect.fit_transform(dataset.data)

    print('X_train_Counts length', X_train_counts.shape)
    print('Number of documents:', len(dataset.data))

    X_data = tfidf_transformer.fit_transform(X_train_counts)
    print('X_data type:', type(X_data))

    new_doc = []
    for values in dataset.data:
        new_doc.append(values.decode('utf-8'))

    """
    #with open(doc, mode='r') as in_file:
        for record in in_file:
            new_doc.append(record)
    """

    # predict the outcome on the testing set and store it in a variable named y_predicted
    y_predicted = pipeline.predict(new_doc)

    counter = 0
    harassment = 0
    no_harassment = 0
    wrong = 0
    for doc, cat in zip(new_doc, y_predicted):
        if cat != dataset.target[counter]:
            #print('<{0}> {1} => {2}  ==> original class: {3}'.format(counter + 1, doc.strip(), category[cat],
            #                                                         category[dataset.target[counter]]))
            wrong += 1
            if category[dataset.target[counter]] == 'harassment':
                harassment += 1
            else:
                no_harassment += 1
        counter += 1

    print('Number of misclassification:', wrong)
    print('Harassment misclassification:', harassment)
    print('No harassment misclassification:', no_harassment)
    print('Success ratio:', (counter - wrong) / counter)

    print('data lenghth', X_data.shape)
    print('cat length', len(dataset.target))

    tfidf_feature_ha = []
    tfidf_feature_no = []
    for vector, category_doc in zip(X_data, dataset.target):
        if category_doc == 0:
            tfidf_feature_ha.append(sum(vector.toarray()[0]))
        else:
            tfidf_feature_no.append(sum(vector.toarray()[0]))

    plt.scatter(range(len(tfidf_feature_ha)), tfidf_feature_ha, color='blue')
    plt.scatter(range(len(tfidf_feature_no)), tfidf_feature_no, color='red')

    plt.title('Tweet TFIDF Representation no_ambiguous Corpus')
    plt.xlabel('Tweet')
    plt.ylabel('Document Sum(TFIDF)')
    plt.show()
    return


if __name__ == '__main__':
    """
    :param model_path: path and filename where model resides
    :param cat_path: path and filename for category nomenclature
    :param doc: path and filename where document resides       
    """

    # record running time
    start = time()
    print('Starting Time: %s' % strftime("%a,  %b %d, %Y at %H:%M:%S", localtime()))

    # checks if path was passed as an argument
    if len(sys.argv) != 4:
        print('Usage: python3 Predictor.py <model_path> <cat_path> <doc_path>')
        sys.exit(-1)

    path = sys.argv[1]
    cat_path = sys.argv[2]
    doc_path = sys.argv[3]

    if not os.path.isfile(path):
        print('\nCould not find model in file: %s' % path)
        print('Usage: python3 Predictor.py <model_path> <cat_path> <doc_path>')
        sys.exit(-1)

    if not os.path.isfile(path):
        print('\nCould not find category file: ' % cat_path)
        print('Usage: python3 Predictor.py <model_path> <cat_path> <doc_path>')
        sys.exit(-1)

    if not os.path.isdir(doc_path):
        print('\nCould not find document: ' % doc_path)
        print('Usage: python3 Predictor.py <model_path> <cat_path> <doc_path>')
        sys.exit(-1)

    predict(path, cat_path, doc_path)

    print('\nEnd Time:  %s' % strftime("%a,  %b %d, %Y at %H:%M:%S", localtime()))
    print('Execution Time: %.2f seconds' % (time()-start))
sys.exit(0)
