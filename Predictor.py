import sys
import os
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.linear_model import SGDClassifier
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.datasets import load_files
from sklearn.model_selection import train_test_split
from sklearn import metrics
from time import strftime, localtime, time
from sklearn.model_selection import cross_val_score, cross_val_predict
from sklearn.model_selection import KFold
from scipy.stats import sem
from matplotlib import pyplot as plt
from sklearn.externals import joblib


"""
    Loads persistence model generated by TClassfier.py and given a body of text makes prediction       
"""

__author__ = 'Plinio H. Vargas'
__date__ = 'Mon,  Oct 16, 2017 at 13:44:27'
__email__ = 'pvargas@cs.odu.edu'


def predict(model, doc):
    """
    :param model: folder where dataset classification sub-folders reside
    :return: void
    """
    encoding = 'utf-8'
    # get title from folder dataset name
    title = model.split('/')
    if title[-1] == '':
        title.pop()

    title = title[-1]

    # load model into pipeline object
    pipeline = joblib.load(model)

    new_doc = []
    no_doc = 50
    for folder in os.listdir(path):
        print(folder)
        print(os.listdir(path + folder))
        for tweet_file in os.listdir(path + folder)[:no_doc]:
            tweet_fhs = open(path + folder + '/' + tweet_file, "r", encoding=encoding)
            new_doc.append(tweet_fhs.read())
            tweet_fhs.close()

    predictions = cross_val_predict(pipeline, docs_test, y_test, cv=cv)

    # predict the outcome on the testing set and store it in a variable named y_predicted
    y_predicted = pipeline.predict(new_doc)

    print()
    print('Prediction index ===> ', y_predicted)
    print()

    counter = 0
    for doc, category in zip(new_doc, y_predicted):
        counter += 1
        print('<{0}> {1} => {2}'.format(counter, doc, dataset.target_names[category]))

    # predict the outcome on the testing set and store it in a variable named y_predicted
    y_predicted = pipeline.predict(docs_test)
    y_prob = pipeline.predict_proba(docs_test)

    return


if __name__ == '__main__':
    """
    :param model_path: path and filename where model resides
    :param doc: path and filename where document resides       
    """

    # record running time
    start = time()
    print('Starting Time: %s' % strftime("%a,  %b %d, %Y at %H:%M:%S", localtime()))

    # checks if path was passed as an argument
    if len(sys.argv) != 3:
        print('Usage: python3 Predictor.py <model_path> <doc_path>')
        sys.exit(-1)

    path = sys.argv[1]
    doc_path = sys.argv[2]

    if not os.path.isfile(path):
        print('\nCould not find model in file: ' % path)
        print('Usage: python3 Predictor.py <model_path> <doc_path>')
        sys.exit(-1)

    if not os.path.isfile(doc_path):
        print('\nCould not find document: ' % doc_path)
        print('Usage: python3 Predictor.py <model_path> <doc_path>')
        sys.exit(-1)

    predict(path)

    print('\nEnd Time:  %s' % strftime("%a,  %b %d, %Y at %H:%M:%S", localtime()))
    print('Execution Time: %.2f seconds' % (time()-start))
sys.exit(0)
